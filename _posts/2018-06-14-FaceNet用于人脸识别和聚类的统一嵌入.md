---
layout: post
title: FaceNet:人脸识别和聚类的统一嵌入论文翻译和解读
categories: [Paper]
description: FaceNet:人脸识别和聚类的统一嵌入
header-mask:  0.3
tags: 
    - CNN
    - 图像识别
    - 人脸识别
---



# FaceNet:人脸识别和聚类的统一嵌入

**摘要**

尽管人脸识别领域最近取得了重大进展[10、14、15、17]，但在规模上有效地实施人脸验证和识别，对当前的研究方法提出了严峻的挑战。在本文中，我们提出了一个叫做FaceNet的系统，它直接从脸部图像学习到一个紧凑的欧几里得空间，距离直接对应于面部相似度的度量。一旦完成了这个空间，就可以通过使用带有FaceNet嵌入特性的标准技术轻松实现人脸识别、验证和集群等任务。 
 我们的方法使用深度卷积网络来直接优化嵌入本身，而不是像之前的深度学习方法那样的中间瓶颈层。为了训练，我们使用一种新颖的在线三重挖掘方法生成的匹配/不匹配的面块。我们的方法的好处是更大的代表性效率:我们实现了最先进的人脸识别性能，每个脸只有128个字节。 
 在广泛使用的LFW数据集上，我们的系统实现了99.63%的新记录精度。在YouTube上，DB达到了95.12%。我们的系统将这两个数据集的错误率降低了30%。

**1 . ** **工作介绍**

在本文中，我们提出了一个统一的人脸识别系统(就是这个人)、识别(此人就是这个人)和聚类(在这些面孔中找到普通的人)。我们的方法是建立在学习一种欧几里得的嵌入每个图像使用一个深度卷积网络。该网络经过训练，使嵌入空间中的平方L2距离直接对应于人脸的相似度:同一个人的面有小距离，不同人群的面距离较大。 
 一旦这种嵌入已经产生，那么上述的任务就会变得很简单:脸验证仅仅涉及到两个嵌入之间的距离的阈值;识别成为k - nn分类问题;可以使用诸如k - means或聚集集群等现成技术实现集群化。 
 先前基于深层网络的人脸识别方法采用了一种分类层[15,17]，在一组已知的人脸识别上进行训练，然后将一个中间的瓶颈层作为一种表征，用于在训练中使用的识别集以外的识别识别。这种方法的缺点是它的不直接性和低效率:人们必须希望瓶颈表示能够很好地推广到新面孔;通过使用一个瓶颈层，每个面的表示尺寸通常非常大(10世纪的尺寸)。最近的一些研究[15]通过使用PCA降低了这种维度的维度，但这是一个线性转换，可以很容易地在网络的一层中学习。 
 与这些方法不同的是，FaceNet直接将其输出训练成一个紧凑的128 - d嵌入，使用基于LMNN的三重损失函数[19]。我们的三胞胎由两个匹配的面部缩略图和一个不匹配的脸缩略图组成，而损失的目标是将积极的对与消极的距离分开。缩略图是脸部区域的致密作物，没有2D或3D对齐，除了缩放和翻译。 
 选择使用哪三胞胎对于获得良好的表现来说是非常重要的，而受课程学习的启发，我们提出了一种新的在线负面范例挖掘策略，它确保了网络训练作为三胞胎的难度不断增加。为了提高聚类的准确性，我们还探索了一种积极的挖掘技术，这种技术鼓励单个人的嵌入。 
 作为我们的方法可以处理的不可思议的可变性，请参见图1。显示的是PIE[13]的图像对，以前被认为是很难的人脸验证系统。

![](img\picture\01\clip_image002.png) 
 图1所示。光照和姿态不变性。姿势与照度是人脸识别中的一个长期存在的问题。这个图显示了相同的人脸和不同的姿势和照明组合的人脸之间的距离。0.0表示两张脸是相同的，4.0对应于相反的光谱，两种不同的恒等式。您可以看到，1.1的阈值将对每一对进行正确的分类。

本文其余部分的概述如下:在第2节中，我们回顾了该领域的文献;第3.1节定义了三重损失，第3.2节描述了我们的新三合选择和训练过程;在第3.3节中，我们描述了所使用的模型架构。最后，在第四节和第五节中，我们给出了一些嵌入的定量结果，并定性地探讨了一些聚类结果。

**2. ** **相关工作**

类似于其他使用深层网络的近期作品[15,17]，我们的方法是一种纯粹的数据驱动方法，它直接从脸部的象素上学习它的表示。我们不使用工程特性，而是使用一个大数据集来达到适当的不变性，以构成、照明和其他变化的条件。 
 在本文中，我们探索了两种不同的深度网络架构，它们最近在计算机视觉社区中取得了巨大的成功。两者都是深度卷积网络[8,11]。第一个架构基于Zeiler&Fergus[22]模型，该模型由多个交错层、非线性激活、局部响应规范化和max池化层组成。我们另外添加几个1×1×d卷积层受[9]的工作。第二个架构基于Szegedy等的初始模型，该模型最近被用作ImageNet 2014的获胜方法[16]。这些网络使用混合层来并行运行多个不同的卷积和汇聚层，并将它们的响应连接起来。我们发现，这些模型可以将参数数量减少多达20倍，并有可能减少类似性能所需的失败次数。 
 有大量的面部验证和识别功能。回顾一下这篇文章的范围，我们只会简单地讨论一下最近最相关的工作。 
 [15,17,23]的作品都采用了复杂的多阶段系统，将一个深卷积网络的输出与PCA进行了维数减少和SVM分类。 
 Zhenyao等人[23]利用一个深度网络将面孔“扭曲”成一个典型的正面视图，然后学习CNN，将每个面孔分类为一个已知的身份。为了进行面部验证，使用了与SVMs集成的网络输出的PCA。 
 Taigman等[17]提出了一种将人脸与通用三维形状模型相结合的多级方法。经过训练，一个多类网络对超过4000个身份进行人脸识别任务。作者还尝试了一个所谓的Siamese网络，他们直接优化了两个脸部特征之间的L - 1距离。他们在LFW上的最佳表现(97.35%)来自三个使用不同的对齐和颜色通道的网络。预测的距离(χ2内核)基础上的非线性支持向量机预测的网络使用非线性支持向量机相结合。 
 Sun等[14,15]提出了一个紧凑的，因此相对便宜的计算网络。他们使用了25个这样的网络，每一个都使用不同的面部贴片。在LFW(99.47%[15])上，作者将50个回复(规则和翻转)结合在一起。采用PCA和联合贝叶斯模型[2]，有效地对应了嵌入空间中的线性变换。他们的方法不需要显式的2D / 3D对齐方式。通过使用分类和验证损失的组合来训练网络。验证损失类似于我们使用的三重损失[12,19]，因为它最小化了相同身份的面之间的L 2 -距离，并在不同身份的面之间设置了一个边界。主要的区别在于，只有对图像进行比较，而三重损失则鼓励相对距离约束。 
 一个类似的损失在这里使用的是wang等人 [18] 由语义和视觉相似性进行的图像排列。

**3.** ** 方法**

FaceNet使用一个深度卷积网络。我们讨论了两个不同的核心架构:Zeiler&Fergus[22]风格的网络和最近的Inception[16]类型网络。这些网络的细节在第3.3节中描述。 
 考虑到模型的细节，并将其视为一个黑盒(见图2)，我们的方法最重要的部分在于整个系统的端到端学习。为此，我们采用三重损失直接反映了我们在人脸验证、识别和集群中所要达到的目标。即,我们争取一个嵌入f(x),从一个图像x到特征空间R d,这样的平方距离所有面孔,独立的成像条件下,相同的身份很小,而平方距离的不同身份的大脸图像。

![这里写图片描述](img\picture\01\clip_image004.png) 
 图2.模型结构。我们的网络由一个批输入层和一个深CNN组成，然后是L 2的标准化，这导致了人脸的嵌入。接下来是训练期间的三重损失。

![这里写图片描述](file:///C:/Users/ZERO/AppData/Local/Temp/msohtmlclip1/01/clip_image006.png) 
 图3。三重损失最小化了锚和相同身份的正值之间的距离，并最大化锚点与不同身份的负值之间的距离。

虽然我们并没有直接与其他损失进行比较，例如，在[14]Eq .(2)中使用成对的阳性和阴性，但我们认为三重损失更适合于面部验证。损失的动机是[14]鼓励所有的面孔一个身份是˘aÿ预计˘´Z到嵌入空间中的一个点。然而，三重损失试图在每一对人脸之间执行一个边界，从一个人脸到所有其他的脸。这样一来，人脸就可以在流形上生存，同时还能保持距离，从而辨别出其他身份。 
 下面的部分描述了这个三重损失，以及如何在缩放后有效地学习它。

**3.1**  **三重损失**

嵌入是由f(x)∈R d。它将一个图像x嵌入d维欧几里得空间。此外，我们将此嵌入限制在d维超球体上，即kf(x)k 2 = 1。这种损失是在近邻分类的背景下产生的。在这里，我们想要确保一个特定的人的图像x a i(锚)更接近所有其他图像x p i(正)，而不是任何其他任何人的图像x i(阴性)。如图3所示。

**3.3**  **深度卷积网络**

在我们所有的实验中，我们基于标准的backprop（后撑）[8,11]和AdaGrad（自适应梯度算法）[5]用随机梯度下降(SGD)来训练CNN。在大多数实验中，我们开始以0.05的学习速度，降低到最终的模型。类似于[16]，模型是随机初始化的，并在CPU集群上进行1000到2000小时的训练。在训练500小时后，损失的减少(和准确性的增加)明显放缓，但是额外的训练仍然可以显著提高性能。边缘值α被设置为0.2。 
 我们使用了两种类型的体系结构，并在实验部分中详细讨论了它们的优缺点。它们的实际区别在于参数和每秒浮点运算次数的不同。最好的模型可能取决于不同的应用。例如，一个在数据中心中运行的模型可以有很多参数，并且需要大量的每秒浮点运算次数，而一个在移动电话上运行的模型需要很少的参数，这样它才能适合内存。我们所有的模型都使用整流线性单位作为非线性激活函数。 
 第一类,如表1所示,添加1×1×d卷积层,如[9]提出，Zeiler&Fergus[22]架构标准的卷积层和结果模型中22层深之间。它总共有1.4亿个参数，每个图像需要大约16亿每秒浮点运算次数。 
 第二个类，我们使用的是基于GoogLeNet的初始模型[16]。这些模型有20×较少的参数(约为6.6M- 7.5M)和相当于5×较少FLOPS(500M~ 1.6B)。其中一些模型的大小(包括深度和过滤器的数量)大大减少了，因此它们可以在移动电话上运行。一个是NNS1，有26M个参数，每个图像只需要220M的FLOPS。另一个NNS2有4.3M个参数和20M的FLOPS。表2详细描述了NN2我们最大的网络。NN3在体系结构上是相同的，但其输入尺寸减少到160x160。NN4的输入大小仅为96x96，因此大大降低了CPU的需求(285M FLOPS VS NN2的1.6B)。除了减少的输入尺寸之外，在较高的层次上，它不使用5x5的卷积，因为那时的接受域已经太小了。一般情况下，我们发现5x5的卷积可以在整个过程中被移除，但精度只有很小的下降。图4比较了我们所有的模型。

![这里写图片描述](img\picture\01\clip_image008.png) 
 表1.NN1。这个表展示了我们Zeiler&Fergus[22]基于1×1卷积模型的结构，灵感来自于[9]。输入和输出的尺寸大小被描述为row（行）×col(列)×#filters（过滤器）。内核被指定为row×col,步幅和最大输出[6]池大小p = 2。

![这里写图片描述](img\picture\01\clip_image010.png)
 表2.NN2。NN2初始化典型的详情。这个模型与[16]中描述的几乎完全相同。两个主要区别是在指定位置使用L 2池化代替了max池(m)化。池化总是3×3(除了最后的平均池化)和与每个初始模块内的卷积模块并行。如果有一个池化后的降维，它表示为p. 1×1,3×3，然后和5×5池化连接得到最终的输出。

**5.****实验**

如果没有提到其他，我们将使用介于100M-200M的训练脸缩略图，其中包括大约800个不同的身份。每个图像上都有一个人脸检测器，每个面部都有一个紧密的边界框。这些脸的缩略图被调整到相应的网络的输入尺寸。在我们的实验中，输入尺寸从96x96像素到224x224像素不等。

**5.1** **计算精度权衡**

在深入研究更具体的实验细节之前，letâ ˘ A ´ Zs讨论了一个特定模型需要的精度与FLOPS数量之间的权衡。图4显示了在x轴上的失败和0.001错误接受率(FAR)的准确性，我们的用户在第4.2节中标记了测试数据。很有趣的是，计算模型所要求的计算和它所达到的精度之间有很强的相关性。这个数字突出了我们在实验中更详细地讨论的五个模型(NN1,NN2,NN3,NNS1,NNS2)。 
 ![这里写图片描述](img\picture\01\clip_image012.png) 
 图4。FLOPS与准确性权衡。显示了在不同模型大小和架构之间的FLOPS和准确性之间的权衡。重点是我们在实验中关注的四个模型。 
 ![这里写图片描述](img\picture\01\clip_image014.png) 
 表3。网络架构。这个表比较了我们的模型架构在执行测试集上的性能(参见4.1)。报告的平均验证率VAL在10 E - 3错误接受率。同样显示的是在五个测试分割中平均值的标准误差。

我们还研究了模型参数数量的准确性权衡。然而，在这种情况下，这张照片并不清楚。例如，基于初始的模型NN2可以获得与NN1相当的性能，但是只有20个参数。不过，每秒的浮点运算次数是具有可比性的。很明显，如果参数数量进一步减少，预计性能将会下降。其他模型架构可能允许进一步的减少而不损失精度，就像在本例中所做的那样。 
 ![这里写图片描述](img\picture\01\clip_image016.png) 
 图5。网络架构。这个图显示了从4.2节开始的个人照片测试的四个不同模型的完整ROC。10 E - 4的急剧下降可以用地面真相标签上的噪音来解释。模型的性能:NN2:224×224输入基于初始模型;NN1:基于Zeiler&Fergus网络1×1的卷积;NNS1:小型初始样式模型，只有220M的每秒浮点运算次数;NNS2:微型初始模型，只有20M的FLOPS。

**5.2 CNN** **模型的作用**

现在，我们将更详细地讨论我们的四个选择模型的性能。一方面我们有我们的传统Zeiler&Fergus基础架构与1×1(22日9)的卷积(见表1)。另一方面，我们建立了基于[16]的模型，极大地减少了模型的大小。总的来说，在最终的性能中，两种架构的顶级模型都可以进行比较。然而，我们的一些基于初始的模型，如NN3，仍然具有良好的性能，同时显著地减少了每秒浮点运算次数和模型的大小。 
 我们的个人照片测试集的详细评估如图5所示。虽然最大的模型在准确性上比微型NNS2有了显著的提高，但后者可以在移动电话上运行30ms /图像，而且可以在人脸聚类中被仍然足够准确的使用。对于FAR < 10e-4,ROC的急剧下降在测试数据的基础上显示出了嘈杂的标签。在极低的误判率下，一个错误标记的图像可以对曲线产生显著的影响。

**5.3** **对图像质量的敏感性**

表4显示了我们的模型在不同的图像大小范围内的鲁棒性。该网络在JPEG（联合照相专家群）压缩方面非常健壮，并且非常好地达到了JPEG 20的质量。当人脸缩略图的尺寸是120x120像素，即使是80x80像素，其性能下降非常小，也能显示出可接受的性能。这是值得注意的，因为该网络接受了220x220输入图像的训练。降低分辨率的训练可以进一步提高这一范围。 
 ![这里写图片描述](img\picture\01\clip_image018.png) 
 表4。图像质量。左边的表显示了在10 E - 3精度上的对验证率的影响，并有不同的JPEG质量。右边的图显示像素图像大小如何影响验证率为10 E - 3精度。这个实验是在NN1的第一次测试全数据集的分离中完成的。

![这里写图片描述](img\picture\01\clip_image020.png) 
 表5所示。嵌入维数。这张表比较了我们的模型NN1的嵌入维度对我们在4.1节中提出的集合的影响。除VAL在10 E - 3之外，我们还显示了在5个分割中计算的均值的标准误差。

**5.4** **嵌入维数**

我们探索了不同的嵌入维度，并选择了128用于所有的实验，而不是在表5中所报告的比较。一个人会期望更大的嵌入至少和较小的嵌入一样好，然而，他们可能需要更多的训练以达到同样的准确性。也就是说，表5中所报告的性能差异在统计上是无关紧要的。 
 应该指出的是，在训练一个128维的浮点向量时，但它可以被量化到128字节而不损失精度。因此，每个人脸都由一个128维字节向量来表示，这对于大规模的聚类和识别是非常理想的。更小的嵌入可能会在很小的精度损失，并且可以在移动设备上使用。

**5.5** **大量的训练数据**

表6显示了大量培训数据的影响。由于时间限制，这个评估在一个较小的模型上运行;在更大的型号上，效果可能更大。很明显，使用数千万个范例会明显提高我们的个人照片测试的准确性，从第4.2节开始。与几百万张图像相比，误差的相对减少率为60%。使用另一个数量级的图像(数以亿计的图像)仍然会有一个小的提升，但是改进逐渐减少。 
 ![这里写图片描述](img\picture\01\clip_image022.png) 
 表6所示。训练数据的大小。这张表比较了700h训练后的性能，它的模型有96x96像素的输入。模型架构类似于NN2，但是没有初始模块中的5x5卷积。 
 ![这里写图片描述](img\picture\01\clip_image024.png) 
 图6。LFW错误。这显示了在LFW上错误分类的所有图像对。

**5.6在LFW上的表现**

我们在LFW上使用不受限制的标准协议来评估我们的模型，标记外部数据。用9个训练分裂来选择L 2距离的阈值。分类(相同或不同)然后在第十次测试拆分中执行。除了第8(1.256)外所有测试拆分，所选最优阈值为1.242。 
 我们的模型以两种模式进行评估： 
 1.LFW提供的缩略图的固定中心裁切； 
 2.一个专有的面部检测器(类似于Picasa[3])在提供的LFW缩略图上运行。如果它不能对齐人脸(这发生在两个图像上)，则使用LFW对齐。 
 图6给出了所有失败案例的概述。它在顶部表示错误接受，在底部表示错误的拒绝。当使用(1)中所描述的固定中心裁切时，我们达到了98.87% （+-0.15）的分类精度，并且在使用额外的人面对齐时打破了99.63% （+-0.09）的标准误差。这减少了在[17]中对DeepFace所报告的错误，超过了7倍的因素，而先前最先进的报告为DeepId2 + 在[15]中增加了30%。这是NN1模型的性能，但即使是更小的NN3也达到了没有统计上显著差异的性能。

**5.7在Youtube Face DB上的表现**

我们在每个视频中使用我们的面部探测器所检测到的前100帧的所有对的平均相似度。这给我们的分类准确率为95.12%（+- 0.39）。使用前1000帧的结果是95.18%。与[17]91.4%相比，其也评价了每个视频的100帧，我们将错误率降低了近一半。DeepId2 +[15]达到了93.2%，我们的方法降低了30%的误差，与我们对LFW的改进相当。

**5.8人脸聚类**

我们紧凑的嵌入使用人脸聚类，以便将用户的个人照片聚集成具有相同身份的人群。与单纯的验证任务相比，分配约束来加强人脸聚类，取得了真正惊人的结果。图7显示了用户个人照片集合中的一个集群，使用合并聚类来生成聚集。这清晰的展示了遮挡，光照，姿势，甚至年龄等不可思议的不变性。 
 ![这里写图片描述](img\picture\01\clip_image026.png) 
 图7 人脸聚类。显示的是一个用户的范例集群。用户个人照片收集的所有图片都聚集在一起。

**6.****总结**

我们提供了一种直接学习嵌入到欧几里得空间的方法来进行人脸验证。这使它有别于使用CNN瓶颈层的其他方法[15,17]，或者需要额外的后处理，例如多个模型和PCA的连接，以及SVM分类。我们的端到端训练既简化了设置，又表明直接优化与手头任务相关的损失提高了性能。 
 我们模型的另一个优点是，它只需要最小的对准(在脸部区域的密集作物)。[17]例如，执行复杂的3D对齐。我们还尝试了相似转换比对，并注意到这实际上可以稍微提高性能。不清楚它是否值得额外的复杂性。 
 未来的工作将集中于更好地理解错误案例，进一步改进模型，并减少模型大小和减少CPU需求。我们还将研究如何改进目前极长的训练时间，例如，伴随着较小批量大小的改变，我们课程学习的变化，以及离线/在线积极和消极的挖掘。

 