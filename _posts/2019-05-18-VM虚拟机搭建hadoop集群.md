---
layout: post
title: VM虚拟机搭建hadoop集群
categories: [Hadoop]
description: VM虚拟机搭建hadoop集群
---

## CentOS安装

### 下载镜像

这里我们使用的是CentOS 7 DVD版本 ，地址：[http://mirrors.aliyun.com/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-1611.iso](http://mirrors.aliyun.com/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-1611.iso)

### 安装系统


新建虚拟机部分就不再赘述，网上有许多资源，主要针对Hadoop环境安装部分做介绍。注意：网络模式请使用NAT模式

由于Hadoop的安装需要用到某些软件和网络，我对这部分安装做一个简短的介绍。

![](/img/picture/centos-1.png)

默认是选中Minimal Install，这个安装之后很多东西要自己手动安装和配置，比较麻烦，因此建议不选这个。如果你喜欢桌面，你还可以选择GNOME Desktop。因为我们同时运行几个虚拟机，比较消耗计算机资源，因此为了减轻压力，不建议安装图像界面，所以我选的是Server。

![](/img/picture/centos-2.png)

开启网络

![](/img/picture/centos-3.png)

打开我们的以太网络

![](/img/picture/centos-4.png)

### 测试远程SSH连接

SSH工具：
http://www.hostbuf.com/t/989.html

使用`ifconfig`获取IP地址
> 如果在安装时候选择的是Minimal  Install或者是没有选择Network & host name进行相关配置，ssh服务是没有安装的，也就没法使用远程工具进行连接。此时你需要用root账户登录，或者使用普通账户登录后用sudo命令获得管理员权限，安装ssh服务。


![](/img/picture/ssh-1.png)

这里我的IP是`192.168.111.140`，使用远程工具通过IP连接

如果安装了SSH命令的也可以使用如下命令连接：

```shell
$ ssh root@192.168.111.140 -p 20 # 20为SSH的默认端口，可不写
```
CentOS中ssh服务相关的命令

```shell

#查找ssh相关程序的命令：

$ rpm  -qa  |  grep  ssh

#查看ssh服务状态的命令：

$ service  sshd  status

#查看是否启动了ssh服务：

$ netstat  -antp  | grep sshd

#安装ssh服务的命令:

$ yum  install  openssh-server

#启动ssh服务命令：

$ service  sshd  start

#重启ssh服务命令：

$ service  sshd  restart

# 停止ssh服务命令：

$ service  sshd  stop

#将ssh服务设置为开机启动：

$ chkconfig  sshd  on

#将ssh服务设置为开机不启动：

$chkconfig  sshd  off

```

## 静态IP固定

我们需要在`虚拟网络编辑器`中找到网关IP、子网掩码，这些信息。

在`编辑`打开`虚拟网络编辑器`，开始点击`NAT模式`，之后在点击`NAT设置`就可以看到我们这些信息了。

![](/img/picture/vm-1.png)

```shell
$ vim /etc/sysconfig/network-scripts/ifcfg-ens33
```

添加或者修改以下内容：
> 注意：IPADDR必须和GATEWAY处于同一个IP段

```shell
IPADDR="192.168.111.106" #你想要设置虚拟机的IP地址
GATEWAY="192.168.111.2" # 默认网关
NETMASK="255.255.255.0" #子网掩码
ONBOOT="yes"
BOOTPROTO="static"
DNS1="8.8.8.8"
DNS2="1.1.1.1"
```

修改完毕之后，重启服务

```shell
$ service network restart
```

如果有报错,请重启虚拟机

```shell
$ reboot
```

测试网络配置

```shell
$ ping www.baidu.com
```

## 配置主机名称

查看当前主机信息

```shell
$ hostnamectl
```

永久修改主机名称

```shell
$ hostnamectl set-hostname geeklp --static
```

再次查看当前主机信息

```shell
$ hostnamectl status
```

还有另外一个方法：
通过修改文件/etc/hostname来实现主机名的修改。把该文件内容替换成自己想要的主机名重启即可。

使用`reboot`重启虚拟机后,我们可以发现欢迎信息中主机名已经改变。

### 修改HOSTS

```shell
$ vim /etc/hosts
```

添加如下内容：

```shell
# 此IP是你当前虚拟机的IP
192.168.111.114 hadoop104
```

重启虚拟机

```shell
$ reboot
````

重启虚拟机之后，在本地电脑（运行虚拟机的电脑）的`C:\Windows\System32\drivers\etc\hosts`中添加

```shell
192.168.111.140 hadoop140
```
保存之后，在`CMD`中使用`ipconfig /flushdns`刷新DNS
> 注意：保存的时候hosts文件是没有任何后缀的

测试时候可以访问虚拟机

```shell
ping 192.168.111.140
```


## 前期准备工作

### hadoop专属用户创建

```shell
$ sudo useradd -m hadoop -s /bin/bash
```

设置密码：

```shell
$ sudo passwd hadoop
```

需要输入两次密码

```shell
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully
```

提升`hadoop`用户的权限为管理员（虽然增加了管理员权限，但后面有些地方还是需要进入root用户进行操作）

编辑`/etc/sudoers`
```shell
$ vim /etc/sudoers
```

添加`红色`方框中的内容到此文件中

![](/img/picture/user-1.png)


切换到`hadoop`用户

```shell
$ su hadoop
```

### 配置SSH无密码登录

SSH设置需要在集群上执行不同的操作，如启动，停止和分布式守护shell操作。进行身份验证不同的Hadoop用户，需要一种用于Hadoop的用户提供的公钥/私钥对，并用不同的用户共享。


```shell
$ ssh-keygen -t rsa
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
$ chmod 755 ~/.ssh
$ chmod 0600 ~/.ssh/authorized_keys
```

验证ssh

```shell
$ ssh localhost
```

接下来可以再次尝试ssh localhost，如若无需再次输入密码，既成功。

### JDK安装

查看是否安装

```shell
$ java -version
```
如果是1.7，卸载当前版本，更换为1.8

查看依赖包

```shell
$ yum list installed | grep java
```

卸载1.7jdk
```shell
$ yum -y remove java-1.7.0-openjdk*  
```

```shell
$ sudo apt-get install openjdk-8-jdk
```
#### 下载JDK
> 需要注册Oracle账号
官网：`https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html`

![](/img/picture/oracle-jdk.png)

下载`jdk-8u211-linux-x64.tar.gz`

```shell
$ cd /usr/local/
$ wget https://download.oracle.com/otn/java/jdk/8u211-b12/478a62b7d4e34b78b671c754eaaf38ab/jdk-8u211-linux-x64.tar.gz?AuthParam=1558191965_2d075bd3a41704e8e152ef0cfd98ba3e
$ tar -zxvf jdk-8u211-linux-x64.tar.gz
```

添加环境变量

```shell
$ vim /etc/profile.d/java.sh
```

输入以下内容：

````shell
export JAVA_HOME=/usr/local/jdk1.8.0_211
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
````

使`source`配置文件生效

```
$ source /etc/profile
```


输出`JAVA_HOME`路径，查看配置是否生效

```shell
$ echo $JAVA_HOME
```

输出以下内容说明配置已经生效

```
$ /usr/local/jdk1.8.0_211
```

查看是否java安装成功

```shell
$ java -version
```

显示以下信息说明安装成功

```
openjdk version "1.8.0_212"
OpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-0ubuntu1.18.04.1-b03)
OpenJDK 64-Bit Server VM (build 25.212-b03, mixed mode)
```

Hadoop
最新版:[http://hadoop.apache.org/releases.html](http://hadoop.apache.org/releases.html)

```shell
$ cd /usr/local/
 
$ wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz 
```
 
```shell
$ tar -vzxf hadoop-3.1.2.tar.gz # 解压

$ mv hadoop-3.1.0  hadoop # 重命名
 
$ cd hadoop
 
$ ./bin/hadoop version
```

你将会看到类似内容：

```
Hadoop 3.1.2
Source code repository https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a
Compiled by sunilg on 2019-01-29T01:39Z
Compiled with protoc 2.5.0
From source with checksum 64b8bdd4ca6e77cce75a93eb09ab2a9
This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.1.2.jar
```

```shell
$ cd /etc/profile.d/
$ sudo vim hadoop.sh
```
输入以下内容:

```shell
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_INSTALL=$HADOOP_HOME
```
应用所有更改到当前正在运行的系统
```shell
$ source /etc/profile
```


配置core-site.xml

core-site.xml文件中包含，如：用于Hadoop实例的端口号，分配给文件系统，存储器限制用于存储数据存储器和读/写缓冲器的大小的信息。

```shell
$ sudo vim /usr/local/hadoop/etc/hadoop/core-site.xml
```

写入以下内容：

```xml
<configuration>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/usr/local/hadoop/tmp</value>
        <description>Abase for other temporary directories.</description>
    </property>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

配置hadoop-env.sh
需要添加JAVA_HOME的路径
```shell
$ echo $JAVA_HOME
```

得到

```shell
/usr/local/jdk1.8.0_211
```

```shell
$ sudo vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh
```

找到被注释掉的JAVA_HOME,填写上面输出的JAVA_HOME地址,取消注释(删除`#`)

```shell
export JAVA_HOME= /usr/local/jdk1.8.0_211
```
配置hdfs-site.xml

hdfs-site.xml文件中包含，如：复制数据的值，NameNode的路径，本地文件系统，要存储Hadoop基础架构的Datanode路径的信息。

```shell
$ sudo vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml
```
写入以下内容：
```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/usr/local/hadoop/tmp/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/usr/local/hadoop/tmp/dfs/data</value>
    </property>
</configuration>
```
上面的文件，所有的属性值是用户定义的，可以根据自己的Hadoop的基础架构进行更改。

配置完成后，执行NameNode的格式化

```shell
$ /usr/local/hadoop/bin/hdfs namenode -format
```

出现类似输出，说明名称节点设置成功

```shell
2019-05-17 16:34:23,646 INFO namenode.FSImageFormatProtobuf: Image file /usr/local/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 393 bytes saved in 0 seconds .
2019-05-17 16:34:23,685 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
2019-05-17 16:34:23,700 INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ZERO.localdomain/127.0.1.1
************************************************************/
```

下面的命令用来启动DFS。执行这个命令将启动Hadoop文件系统。

这里不能再root下运行，切换到 hadoop用户下运行

```shell 
$ sudo /usr/local/hadoop/sbin/start-dfs.sh
```

出现权限问题

```shell
Starting namenodes on [localhost]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
Starting secondary namenodes [account.jetbrains.com]
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.
```
运行 `sudo chown -R hadoop:root /usr/local/hadoop`命令，把hadoop目录所有用户改到hadoop上。

再次运行
```shell
# 注意：不能加sudo
$ /usr/local/hadoop/sbin/start-dfs.sh
```

出现类似输出，说明安装成功：

```shell
Starting namenodes on [localhost]
localhost: namenode is running as process 16525.  Stop it first.
Starting datanodes
Starting secondary namenodes [account.jetbrains.com]
account.jetbrains.com: secondarynamenode is running as process 16988.  Stop it first.
2019-05-17 17:04:20,232 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
```

至此，完成配置，可通过jps查看是否启动成功。

```shell
$ jps
```

结果：

```shell
16988 SecondaryNameNode
16525 NameNode
18269 Jps
```

访问Hadoop上
访问Hadoop的默认端口号为9870。使用以下网址，以获取Hadoop服务在浏览器中。

```shell
$ curl http://localhost:9870 
```

or

```shell
$ curl http://172.0.0.1:9870 
```

or

```shell
$ curl http://192.168.111.140:9870 
```

出现如下内容说明内网可以访问，配置成功：

```html
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="REFRESH" content="0;url=dfshealth.html" />
<title>Hadoop Administration</title>
</head>
</html>
```

如果发现无法访问,手动修改hdfs-site.xml，
修改hdfs-site.xml

```shell
$ sudo vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml
```
 添加如下：

```xml
<property>
  <name>dfs.http.address</name>
  <value>0.0.0.0:9870</value>
</property>

```

对外开放`9870`端口

查看是否开放
```shell
$ firewall-cmd --query-port=9870/tcp # 
````

如果`9870`端口没有被开放，使用下面命令开放端口

```shell
$ sudo firewall-cmd --zone=public --add-port=9870/tcp --permanent
$ firewall-cmd --reload #重载防火墙
```

在本地电脑(安装虚拟机的电脑)的浏览器访问`http://192.168.111.140:9870`

![](/img/picture/hadoop-1.png)


```shell
$ sudo vi /usr/local/hadoop/etc/hadoop/yarn-site.xml
```

修改如下内容：

```shell
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

mapred-site.xml

此文件用于指定MapReduce框架以使用。默认情况下Hadoop包含yarn-site.xml模板。首先，它需要从mapred-site.xml复制模板到mapred-site.xml文件，使用下面的命令来。

```shell
$ sudo vim /usr/local/hadoop/etc/hadoop/mapred-site.xml
```
提供一个默认的`mapred-site.xml`配置文件:[mapred-default.xml](/file/mapred-default.xml)
将默认的文件复制到`mapred-site.xml`中，并添加`<configuration> `和` </configuration>`标签之间添加以下属性

```xml
<configuration> <!--复制时不包含configuration标签-->
<property>
 <name>mapreduce.framework.name</name>
 <value>yarn</value>
 </property>
</configuration>
```

获取启动，执行此命令将启动yarn守护进程。

```shell
$ /usr/local/hadoop/sbin/start-yarn.sh
```

启动之后，执行
```shell
$ jps
```

如果出现如下内容，说明成功

```shell
10529 SecondaryNameNode
13089 ResourceManager
44193 Jps
10103 NameNode
13256 NodeManager
```

测试访问

```shell
$ curl http://192.168.111.140:8088/cluster
```

```html
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
  <meta http-equiv="X-UA-Compatible" content="IE=8">
  <meta http-equiv="Content-type" content="text/html; charset=UTF-8">
  <style type="text/css">
    #apps_paginate span {font-weight:normal}
    #apps .progress {width:8em}
    #apps_processing {top:-1.5em; font-size:1em;
      color:#000; background:#fefefe}

......
````

查看是否开放

```shell
$ firewall-cmd --query-port=8088/tcp # 
````

```shell
$ sudo firewall-cmd --zone=public --add-port=8088/tcp --permanent
$ firewall-cmd --reload #重载防火墙
```

[http://192.168.111.140:8088/](http://192.168.111.140:8088/)

![](/img/picture/hadoop-2.png)

之后需要要启动Hadoop直接使用以下命令：

```shell
$ /usr/local/hadoop/sbin/start-all.sh
```